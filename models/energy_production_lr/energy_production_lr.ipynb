{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2020-2021 Adrian Georg Herrmann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../../data\"\n",
    "\n",
    "locations = {\n",
    "    \"berlin\": [\"52.4652025\", \"13.3412466\"],\n",
    "    \"wijchen\": [\"51.8235504\", \"5.7329005\"]\n",
    "}\n",
    "dfs = { \"berlin\": None, \"wijchen\": None }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sunlight angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_julian_day(time):\n",
    "    if time.month > 2:\n",
    "        y = time.year\n",
    "        m = time.month\n",
    "    else:\n",
    "        y = time.year - 1\n",
    "        m = time.month + 12\n",
    "    d = time.day + time.hour / 24 + time.minute / 1440 + time.second / 86400\n",
    "    b = 2 - np.floor(y / 100) + np.floor(y / 400)\n",
    "\n",
    "    jd = np.floor(365.25 * (y + 4716)) + np.floor(30.6001 * (m + 1)) + d + b - 1524.5\n",
    "    return jd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle(time, latitude, longitude):\n",
    "    # Source: \n",
    "    # https://de.wikipedia.org/wiki/Sonnenstand#Genauere_Ermittlung_des_Sonnenstandes_f%C3%BCr_einen_Zeitpunkt\n",
    "\n",
    "    # 1. Eclipctical coordinates of the sun\n",
    "\n",
    "    # Julian day\n",
    "    jd = get_julian_day(time)\n",
    "\n",
    "    n = jd - 2451545\n",
    "\n",
    "    # Median ecliptic longitude of the sun<\n",
    "    l = np.mod(280.46 + 0.9856474 * n, 360)\n",
    "\n",
    "    # Median anomaly\n",
    "    g = np.mod(357.528 + 0.9856003 * n, 360)\n",
    "\n",
    "    # Ecliptic longitude of the sun\n",
    "    lbd = l + 1.915 * np.sin(np.radians(g)) + 0.01997 * np.sin(np.radians(2*g))\n",
    "\n",
    "\n",
    "    # 2. Equatorial coordinates of the sun\n",
    "\n",
    "    # Ecliptic\n",
    "    eps = 23.439 - 0.0000004 * n\n",
    "\n",
    "    # Right ascension\n",
    "    alpha = np.degrees(np.arctan(np.cos(np.radians(eps)) * np.tan(np.radians(lbd))))\n",
    "    if np.cos(np.radians(lbd)) < 0:\n",
    "        alpha += 180\n",
    "\n",
    "    # Declination\n",
    "    delta = np.degrees(np.arcsin(np.sin(np.radians(eps)) * np.sin(np.radians(lbd))))\n",
    "\n",
    "\n",
    "    # 3. Horizontal coordinates of the sun\n",
    "\n",
    "    t0 = (get_julian_day(time.replace(hour=0, minute=0, second=0)) - 2451545) / 36525\n",
    "\n",
    "    # Median sidereal time\n",
    "    theta_hg = np.mod(6.697376 + 2400.05134 * t0 + 1.002738 * (time.hour + time.minute / 60), 24)\n",
    "\n",
    "    theta_g = theta_hg * 15\n",
    "    theta = theta_g + longitude\n",
    "\n",
    "    # Hour angle of the sun\n",
    "    tau = theta - alpha\n",
    "\n",
    "    # Elevation angle\n",
    "    h = np.cos(np.radians(delta)) * np.cos(np.radians(tau)) * np.cos(np.radians(latitude))\n",
    "    h += np.sin(np.radians(delta)) * np.sin(np.radians(latitude))\n",
    "    h = np.degrees(np.arcsin(h))\n",
    "\n",
    "    return (h if h > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location, _ in locations.items():\n",
    "    # This list contains all time points for which energy measurements exist, therefore delimiting\n",
    "    # the time frame that is to our interest.\n",
    "    energy = {}\n",
    "\n",
    "    data_path = os.path.join(data_root, location)\n",
    "    for filename in os.listdir(data_path):\n",
    "        with open(os.path.join(data_path, filename), \"r\") as file:\n",
    "            for line in file:\n",
    "                key = datetime.strptime(line.split(\";\")[0], '%Y-%m-%d %H:%M:%S').timestamp()\n",
    "                energy[key] = int(line.split(\";\")[1].strip())\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        data={\"time\": energy.keys(), \"energy\": energy.values()},\n",
    "        columns=[\"time\", \"energy\"]\n",
    "    )\n",
    "    dfs[location] = df.sort_values(by=\"time\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize energy data per hour instead of keeping it per 15 minutes\n",
    "\n",
    "for location, _ in locations.items():\n",
    "    times = []\n",
    "    energy = []\n",
    "\n",
    "    df = dfs[location]\n",
    "    for i, row in dfs[location].iterrows():\n",
    "        if row[\"time\"] % 3600 == 0:\n",
    "            try:\n",
    "                t4 = row[\"time\"]\n",
    "                e4 = row[\"energy\"]\n",
    "                e3 = df[\"energy\"][df[\"time\"] == t4 - 900].values[0]\n",
    "                e2 = df[\"energy\"][df[\"time\"] == t4 - 1800].values[0]\n",
    "                e1 = df[\"energy\"][df[\"time\"] == t4 - 2700].values[0]\n",
    "\n",
    "                times += [t4]\n",
    "                energy += [e1 + e2 + e3 + e4]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    df = pd.DataFrame(data={\"time\": times, \"energy_h\": energy}, columns=[\"time\", \"energy_h\"])\n",
    "    df = df.sort_values(by=\"time\", ascending=True)\n",
    "    dfs[location] = dfs[location].join(df.set_index(\"time\"), on=\"time\", how=\"right\").drop(\"energy\", axis=1)\n",
    "    dfs[location].rename(columns={\"energy_h\": \"energy\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lists contain the time tuples that delimit connected ranges without interruptions.\n",
    "time_delimiters = {}\n",
    "\n",
    "for location, _ in locations.items():\n",
    "    delimiters = []\n",
    "    df = dfs[location]\n",
    "\n",
    "    next_couple = [df[\"time\"].iloc[0], None]\n",
    "    interval = df[\"time\"].iloc[1] - df[\"time\"].iloc[0]\n",
    "    for i in range(len(df[\"time\"].index) - 1):\n",
    "        if df[\"time\"].iloc[i+1] - df[\"time\"].iloc[i] > interval:\n",
    "            next_couple[1] = df[\"time\"].iloc[i]\n",
    "            delimiters += [next_couple]\n",
    "            next_couple = [df[\"time\"].iloc[i+1], None]\n",
    "    next_couple[1] = df[\"time\"].iloc[-1]\n",
    "    delimiters += [next_couple]\n",
    "\n",
    "    time_delimiters[location] = delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This are lists of dataframes containing connected ranges without interruptions.\n",
    "\n",
    "dataframes_wijchen = []\n",
    "for x in time_delimiters[\"wijchen\"]:\n",
    "    dataframes_wijchen += [dfs[\"wijchen\"].loc[(dfs[\"wijchen\"].time >= x[0]) & (dfs[\"wijchen\"].time <= x[1])]]\n",
    "\n",
    "dataframes_berlin = []\n",
    "for x in time_delimiters[\"berlin\"]:\n",
    "    dataframes_berlin += [dfs[\"berlin\"].loc[(dfs[\"berlin\"].time >= x[0]) & (dfs[\"berlin\"].time <= x[1])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location, _ in locations.items():\n",
    "    print(location, \":\")\n",
    "    for delimiters in time_delimiters[location]:\n",
    "        t0 = datetime.fromtimestamp(delimiters[0])\n",
    "        t1 = datetime.fromtimestamp(delimiters[1])\n",
    "        print(t0, \"-\", t1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wijchen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataframes_wijchen:\n",
    "    print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(200, 25))\n",
    "plt.plot(dfs[\"wijchen\"][\"time\"], dfs[\"wijchen\"][\"energy\"], drawstyle=\"steps-pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_max_wijchen = dfs[\"wijchen\"][\"energy\"].max()\n",
    "energy_max_wijchen_idx = dfs[\"wijchen\"][\"energy\"].argmax()\n",
    "energy_max_wijchen_time = datetime.fromtimestamp(dfs[\"wijchen\"][\"time\"].iloc[energy_max_wijchen_idx])\n",
    "\n",
    "print(energy_max_wijchen_time, \":\", energy_max_wijchen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_avg_wijchen = dfs[\"wijchen\"][\"energy\"].mean()\n",
    "print(energy_avg_wijchen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berlin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataframes_berlin:\n",
    "    print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(200, 25))\n",
    "plt.plot(dfs[\"berlin\"][\"time\"], dfs[\"berlin\"][\"energy\"], drawstyle=\"steps-pre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_max_berlin = dfs[\"berlin\"][\"energy\"].max()\n",
    "energy_max_berlin_idx = dfs[\"berlin\"][\"energy\"].argmax()\n",
    "energy_max_berlin_time = datetime.fromtimestamp(dfs[\"berlin\"][\"time\"].iloc[energy_max_berlin_idx])\n",
    "\n",
    "print(energy_max_berlin_time, \":\", energy_max_berlin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_avg_berlin = dfs[\"berlin\"][\"energy\"].mean()\n",
    "print(energy_avg_berlin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sunlight angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location, lonlat in locations.items():\n",
    "    angles = [\n",
    "        get_angle(\n",
    "            datetime.fromtimestamp(x - 3600), float(lonlat[0]), float(lonlat[1])\n",
    "        ) for x in dfs[location][\"time\"]\n",
    "    ]\n",
    "    dfs[location][\"angles\"] = angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contact the author for a sample of data, see doc/thesis.pdf, page 72.\n",
    "weather_data = np.load(os.path.join(data_root, \"weather.npy\"), allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no cloud cover data for berlin2, so use the data of berlin1.\n",
    "weather_data[\"berlin2\"][\"cloud\"] = weather_data[\"berlin1\"][\"cloud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no radiation data for berlin1, so use the data of berlin2.\n",
    "weather_data[\"berlin1\"][\"rad\"] = weather_data[\"berlin2\"][\"rad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess weather data\n",
    "weather_params = [ \"temp\", \"humid\", \"press\", \"cloud\", \"rad\" ]\n",
    "stations = [ \"wijchen1\", \"wijchen2\", \"berlin1\", \"berlin2\" ]\n",
    "\n",
    "for station in stations:\n",
    "    for param in weather_params:\n",
    "        to_del = []\n",
    "        for key, val in weather_data[station][param].items():\n",
    "            if val is None:\n",
    "                to_del.append(key)\n",
    "        for x in to_del:\n",
    "            del weather_data[station][param][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_map(map, time_range):\n",
    "    ret = {\n",
    "        \"time\": [],\n",
    "        \"value\": []\n",
    "    }\n",
    "    keys = list(map.keys())\n",
    "    values = list(map.values())\n",
    "    f = interpolate.interp1d(keys, values)\n",
    "    ret[\"time\"] = time_range\n",
    "    ret[\"value\"] = f(ret[\"time\"])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df(df, time_range, map1, map2, param1, param2):\n",
    "    map1_ = interpolate_map(map1, time_range)\n",
    "    df1 = pd.DataFrame(\n",
    "        data={\"time\": map1_[\"time\"], param1: map1_[\"value\"]},\n",
    "        columns=[\"time\", param1]\n",
    "    )\n",
    "\n",
    "    map2_ = interpolate_map(map2, time_range)\n",
    "    df2 = pd.DataFrame(\n",
    "        data={\"time\": map2_[\"time\"], param2: map2_[\"value\"]},\n",
    "        columns=[\"time\", param2]\n",
    "    )\n",
    "\n",
    "    df_ = df.join(df1.set_index(\"time\"), on=\"time\").join(df2.set_index(\"time\"), on=\"time\")\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert weather data into dataframes\n",
    "for location, _ in locations.items():\n",
    "    df = dfs[location]\n",
    "    station1 = location + \"1\"\n",
    "    station2 = location + \"2\"\n",
    "\n",
    "    for param in weather_params:\n",
    "        param1 = param + \"1\"\n",
    "        param2 = param + \"2\"\n",
    "        df = update_df(\n",
    "            df, df[\"time\"], weather_data[station1][param], weather_data[station2][param], param1, param2\n",
    "        )\n",
    "\n",
    "    dfs[location] = df.set_index(keys=[\"time\"], drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are lists of dataframes containing connected ranges without interruptions.\n",
    "\n",
    "dataframes_wijchen = []\n",
    "for x in time_delimiters[\"wijchen\"]:\n",
    "    dataframes_wijchen += [dfs[\"wijchen\"].loc[(dfs[\"wijchen\"].time >= x[0]) & (dfs[\"wijchen\"].time <= x[1])]]\n",
    "\n",
    "dataframes_berlin = []\n",
    "for x in time_delimiters[\"berlin\"]:\n",
    "    dataframes_berlin += [dfs[\"berlin\"].loc[(dfs[\"berlin\"].time >= x[0]) & (dfs[\"berlin\"].time <= x[1])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wijchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dataframes_wijchen[9].iloc[17:258]\n",
    "# df_train = dataframes_wijchen[9].iloc[17:234]\n",
    "# df_train = pd.concat([dataframes_wijchen[9].iloc[17:], dataframes_wijchen[10], dataframes_wijchen[11]])\n",
    "\n",
    "df_val = dataframes_wijchen[-3].iloc[:241]\n",
    "# df_val = dataframes_wijchen[-2].iloc[:241]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_x1 = df_train[[\"angles\", \"temp1\", \"humid1\", \"press1\", \"cloud1\", \"rad1\"]].to_numpy()\n",
    "lr_y1 = df_train[[\"energy\"]].to_numpy()\n",
    "\n",
    "lr_model1 = LinearRegression()\n",
    "lr_model1.fit(lr_x1, lr_y1)\n",
    "lr_model1.score(lr_x1, lr_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_x2 = df_train[[\"angles\", \"temp2\", \"humid2\", \"press2\", \"cloud2\", \"rad2\"]].to_numpy()\n",
    "lr_y2 = df_train[[\"energy\"]].to_numpy()\n",
    "\n",
    "lr_model2 = LinearRegression()\n",
    "lr_model2.fit(lr_x2, lr_y2)\n",
    "lr_model2.score(lr_x2, lr_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_x3 = df_train[[\"angles\", \"temp1\", \"temp2\", \"humid1\", \"humid2\", \"press1\", \"press2\", \"cloud1\", \"cloud2\", \"rad1\", \"rad2\"]].to_numpy()\n",
    "lr_y3 = df_train[[\"energy\"]].to_numpy()\n",
    "\n",
    "lr_model3 = LinearRegression()\n",
    "lr_model3.fit(lr_x3, lr_y3)\n",
    "lr_model3.score(lr_x3, lr_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"lr_model.pkl\"\n",
    "# with open(filename, 'wb') as file:\n",
    "#     pickle.dump(lr_model3, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = df_train[\"time\"].iloc[::24]\n",
    "\n",
    "lr_x3 = df_train[[\"angles\", \"temp1\", \"temp2\", \"humid1\", \"humid2\", \"press1\", \"press2\", \"cloud1\", \"cloud2\", \"rad1\", \"rad2\"]].to_numpy()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 5))\n",
    "\n",
    "ax.set_xticks(ticks=xticks)\n",
    "ax.set_xticklabels(labels=[datetime.fromtimestamp(x).strftime(\"%d-%m-%y\") for x in xticks])\n",
    "ax.tick_params(labelsize=18)\n",
    "ax.plot(df_train[\"time\"], df_train[\"energy\"], label=\"Actual energy production in Wh\", drawstyle=\"steps-pre\")\n",
    "ax.plot(df_train[\"time\"], lr_model3.predict(lr_x3), label=\"Predicted energy production in Wh (Volkel + Deelen)\", drawstyle=\"steps-pre\")\n",
    "ax.legend(prop={'size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = df_val[\"time\"].iloc[::24]\n",
    "\n",
    "lr_x1 = df_val[[\"angles\", \"temp1\", \"humid1\", \"press1\", \"cloud1\", \"rad1\"]].to_numpy()\n",
    "lr_x2 = df_val[[\"angles\", \"temp2\", \"humid2\", \"press2\", \"cloud2\", \"rad2\"]].to_numpy()\n",
    "lr_x3 = df_val[[\"angles\", \"temp1\", \"temp2\", \"humid1\", \"humid2\", \"press1\", \"press2\", \"cloud1\", \"cloud2\", \"rad1\", \"rad2\"]].to_numpy()\n",
    "\n",
    "print(lr_model1.score(lr_x1, df_val[[\"energy\"]].to_numpy()))\n",
    "print(lr_model2.score(lr_x2, df_val[[\"energy\"]].to_numpy()))    \n",
    "print(lr_model3.score(lr_x3, df_val[[\"energy\"]].to_numpy()))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 5))\n",
    "\n",
    "ax.set_xticks(ticks=xticks)\n",
    "ax.set_xticklabels(labels=[datetime.fromtimestamp(x).strftime(\"%d-%m-%y\") for x in xticks])\n",
    "ax.tick_params(labelsize=18)\n",
    "ax.plot(df_val[\"time\"], df_val[\"energy\"], label=\"Actual energy production in Wh\", drawstyle=\"steps-pre\")\n",
    "ax.plot(df_val[\"time\"], lr_model3.predict(lr_x3), label=\"Predicted energy production in Wh (Volkel + Deelen)\", drawstyle=\"steps-pre\")\n",
    "ax.legend(prop={'size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"angles\"].min(), df_val[\"angles\"].max())\n",
    "print(df[\"angles\"].min(), df_train[\"angles\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Berlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dataframes_berlin[1].iloc[:241]\n",
    "# df_train = dataframes_berlin[1].iloc[:720]\n",
    "\n",
    "df_val = dataframes_berlin[1].iloc[312:553]\n",
    "# df_val = dataframes_berlin[1].iloc[720:961]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_x1 = df_train[[\"angles\", \"temp1\", \"humid1\", \"press1\", \"cloud1\", \"rad1\"]].to_numpy()\n",
    "lr_y1 = df_train[[\"energy\"]].to_numpy()\n",
    "\n",
    "lr_model1 = LinearRegression()\n",
    "lr_model1.fit(lr_x1, lr_y1)\n",
    "lr_model1.score(lr_x1, lr_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_x2 = df_train[[\"angles\", \"temp2\", \"humid2\", \"press2\", \"cloud2\", \"rad2\"]].to_numpy()\n",
    "lr_y2 = df_train[[\"energy\"]].to_numpy()\n",
    "\n",
    "lr_model2 = LinearRegression()\n",
    "lr_model2.fit(lr_x2, lr_y2)\n",
    "lr_model2.score(lr_x2, lr_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_x3 = df_train[[\"angles\", \"temp1\", \"temp2\", \"humid1\", \"humid2\", \"press1\", \"press2\", \"cloud1\", \"cloud2\", \"rad1\", \"rad2\"]].to_numpy()\n",
    "lr_y3 = df_train[[\"energy\"]].to_numpy()\n",
    "\n",
    "lr_model3 = LinearRegression()\n",
    "lr_model3.fit(lr_x3, lr_y3)\n",
    "lr_model3.score(lr_x3, lr_y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"lr_model.pkl\"\n",
    "# with open(filename, 'wb') as file:\n",
    "#     pickle.dump(lr_model3, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = df_train[\"time\"].iloc[::24]\n",
    "\n",
    "lr_x3 = df_train[[\"angles\", \"temp1\", \"temp2\", \"humid1\", \"humid2\", \"press1\", \"press2\", \"cloud1\", \"cloud2\", \"rad1\", \"rad2\"]].to_numpy()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 5))\n",
    "\n",
    "ax.set_xticks(ticks=xticks)\n",
    "ax.set_xticklabels(labels=[datetime.fromtimestamp(x).strftime(\"%d-%m-%y\") for x in xticks])\n",
    "ax.tick_params(labelsize=18)\n",
    "ax.plot(df_train[\"time\"], df_train[\"energy\"], label=\"Actual energy production in Wh\", drawstyle=\"steps-pre\")\n",
    "ax.plot(df_train[\"time\"], lr_model3.predict(lr_x3), label=\"Predicted energy production in Wh\", drawstyle=\"steps-pre\")\n",
    "ax.legend(prop={'size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = df_val[\"time\"].iloc[::24]\n",
    "\n",
    "lr_x1 = df_val[[\"angles\", \"temp1\", \"humid1\", \"press1\", \"cloud1\", \"rad1\"]].to_numpy()\n",
    "lr_x2 = df_val[[\"angles\", \"temp2\", \"humid2\", \"press2\", \"cloud2\", \"rad2\"]].to_numpy()\n",
    "lr_x3 = df_val[[\"angles\", \"temp1\", \"temp2\", \"humid1\", \"humid2\", \"press1\", \"press2\", \"cloud1\", \"cloud2\", \"rad1\", \"rad2\"]].to_numpy()\n",
    "\n",
    "print(lr_model1.score(lr_x1, df_val[[\"energy\"]].to_numpy()))\n",
    "print(lr_model2.score(lr_x2, df_val[[\"energy\"]].to_numpy()))\n",
    "print(lr_model3.score(lr_x3, df_val[[\"energy\"]].to_numpy()))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 5))\n",
    "\n",
    "ax.set_xticks(ticks=xticks)\n",
    "ax.set_xticklabels(labels=[datetime.fromtimestamp(x).strftime(\"%d-%m-%y\") for x in xticks])\n",
    "ax.tick_params(labelsize=18)\n",
    "ax.plot(df_val[\"time\"], df_val[\"energy\"], label=\"Actual energy production in Wh\", drawstyle=\"steps-pre\")\n",
    "ax.plot(df_val[\"time\"], lr_model3.predict(lr_x3), label=\"Predicted energy production in Wh\", drawstyle=\"steps-pre\")\n",
    "ax.legend(prop={'size': 18})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}